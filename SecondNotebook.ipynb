{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4a322f9b-696c-4945-9442-1c2d81988f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import zipfile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4a42001f-39ef-42f4-9bfb-305aa69247b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_path = 'Property_data-20250109T055141Z-001.zip'  # Ensure the correct file name\n",
    "extract_path = 'Property_data'\n",
    "\n",
    "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extract_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e13dc646-6073-4f3c-a856-9204752f308c",
   "metadata": {},
   "outputs": [],
   "source": [
    "property_data_folder = extract_path\n",
    "csv_files = [file for file in os.listdir(property_data_folder) if file.endswith('.csv')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "38127172-a43a-4418-84cb-fcf9f0c2deb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error concatenating DataFrames: No objects to concatenate\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Merge all CSV files in the extracted folder with column alignment\n",
    "csv_files = [file for file in os.listdir(property_data_folder) if file.endswith('.csv')]\n",
    "\n",
    "# Initialize an empty list to store data frames\n",
    "data_frames = []\n",
    "\n",
    "# Read each CSV file ands the files\n",
    "all_columns = set()\n",
    "for df in data_frames:\n",
    "    all_columns.update(df.columns)\n",
    "\n",
    "# Convert columns to a sorted list for consistent ordering\n",
    "all_columns = sorted(all_columns)\n",
    "\n",
    "# Standardize all DataFrames to have the same columns\n",
    "standardized_data_frames = []\n",
    "for i, df in enumerate(data_frames):\n",
    "    try:\n",
    "        standardized_df = df.reindex(columns=all_columns, fill_value=None)\n",
    "        standardized_data_frames.append(standardized_df)\n",
    "    except Exception as e:\n",
    "        print(f\"Error reindexing DataFrame from file {csv_files[i]}: {e}\")\n",
    "\n",
    "# Concatenate standardized DataFrames\n",
    "try:\n",
    "    property_data = pd.concat(standardized_data_frames, ignore_index=True)\n",
    "    print(\"Shape of merged data:\", property_data.shape)\n",
    "    print(property_data.head())\n",
    "except Exception as e:\n",
    "    print(f\"Error concatenating DataFrames: {e}\") check its structure\n",
    "for file in csv_files:\n",
    "    file_path = os.path.join(property_data_folder, file)\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        data_frames.append(df)\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {file}: {e}\")\n",
    "\n",
    "# Identify the union of all columns acros\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f13ed901-d1b0-41dd-b59c-69db09835f63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of merged property data: (170611, 2)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Step 1: Define the folder where property data CSVs are located\n",
    "property_data_folder = '.'  # Current directory\n",
    "\n",
    "# Step 2: Merge all CSV files in the folder\n",
    "csv_files = [file for file in os.listdir(property_data_folder) if file.endswith('.csv')]\n",
    "\n",
    "# Initialize an empty list to store DataFrames\n",
    "data_frames = []\n",
    "\n",
    "# Read each file\n",
    "for file in csv_files:\n",
    "    file_path = os.path.join(property_data_folder, file)\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        data_frames.append(df)\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {file}: {e}\")\n",
    "\n",
    "# Identify all columns across files\n",
    "all_columns = sorted(set.union(*(set(df.columns) for df in data_frames)))\n",
    "\n",
    "# Standardize DataFrames to have consistent columns\n",
    "standardized_data_frames = [df.reindex(columns=all_columns, fill_value=None) for df in data_frames]\n",
    "\n",
    "# Concatenate the DataFrames\n",
    "property_data = pd.concat(standardized_data_frames, ignore_index=True)\n",
    "\n",
    "print(\"Shape of merged property data:\", property_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2c827fae-2ae5-4fa7-ae50-395711a20be3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Shape of Combined Property Data: (170611, 2)\n"
     ]
    }
   ],
   "source": [
    "final_shape = property_data.shape\n",
    "print(f\"Final Shape of Combined Property Data: {final_shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5f0ddccf-10c0-4da1-91e5-be61315b1070",
   "metadata": {},
   "outputs": [],
   "source": [
    "property_data_folder = './'  # Current directory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2ad983bf-a211-4038-9648-88c6df8e987b",
   "metadata": {},
   "outputs": [],
   "source": [
    "property_data_folder = './property_data'  # Adjust this based on the actual subfolder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f2e24c20-050b-4ffb-8555-278ab397f58d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['property_interactions.csv']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "property_data_folder = './'  # Update with the correct path\n",
    "csv_files = [file for file in os.listdir(property_data_folder) if file.endswith('.csv')]\n",
    "\n",
    "print(csv_files)  # Check the list of CSV files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "50897394-1b86-4796-8e7a-ca742bac4e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frames = []\n",
    "for file in csv_files:\n",
    "    file_path = os.path.join(property_data_folder, file)\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        data_frames.append(df)\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {file}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bdfd76d8-f7b3-4673-a0fd-961834a4406e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_columns = set()\n",
    "for df in data_frames:\n",
    "    all_columns.update(df.columns)\n",
    "\n",
    "all_columns = sorted(all_columns)  # Sort for consistent order\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5368395c-bf01-4c72-85ee-cdfae2c1a5a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of merged data: (170611, 2)\n",
      "                        property_id         request_date\n",
      "0  ff808081469fd6e20146a5af948000ea  2017-03-10 17:42:34\n",
      "1  ff808081469fd6e20146a5af948000ea  2017-03-09 15:51:17\n",
      "2  ff808081469fd6e20146a5af948000ea  2017-03-10 17:30:22\n",
      "3  ff808081469fd6e20146a5af948000ea  2017-03-11 17:48:46\n",
      "4  ff8080814702d3d10147068359d200cd  2017-03-30 19:59:15\n"
     ]
    }
   ],
   "source": [
    "standardized_data_frames = []\n",
    "for df in data_frames:\n",
    "    standardized_df = df.reindex(columns=all_columns, fill_value=None)\n",
    "    standardized_data_frames.append(standardized_df)\n",
    "\n",
    "try:\n",
    "    property_data = pd.concat(standardized_data_frames, ignore_index=True)\n",
    "    print(\"Shape of merged data:\", property_data.shape)\n",
    "    print(property_data.head())\n",
    "except Exception as e:\n",
    "    print(f\"Error concatenating DataFrames: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c6e7d011-8da7-4f52-941c-3d1d4942a88b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: C:\\Users\\varsh\\OneDrive\\Desktop\\INNOMATICS\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(\"Current working directory:\", os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "50316079-ced0-4cec-8815-7804193987b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.ipynb_checkpoints', 'anaconda_projects', 'FisrtNotebook.ipynb', 'Property_data', 'Property_data-20250109T055141Z-001.zip', 'property_interactions.csv', 'property_photos.tsv', 'Untitled.ipynb']\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir())  # List all files in the current directory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2cb4a6-f6ce-4682-91c4-fa3ac349cb61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8096d79-210f-41f4-8c9d-dddfcd8fe40f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
